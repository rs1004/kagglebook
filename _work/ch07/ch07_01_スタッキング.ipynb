{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../input/sample-data/train_preprocessed.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('../../input/sample-data/test_preprocessed.csv')\n",
    "\n",
    "# neural net用のデータ\n",
    "train_nn = pd.read_csv('../../input/sample-data/train_preprocessed_onehot.csv')\n",
    "train_x_nn = train_nn.drop(['target'], axis=1)\n",
    "train_y_nn = train_nn['target']\n",
    "test_x_nn = pd.read_csv('../../input/sample-data/test_preprocessed_onehot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スタッキング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from models import Model1Xgb, Model1NN, Model2Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainデータを4分割し、3つで学習したモデルで残り1つを予測＆このモデルでtestデータを予測。\n",
    "# trainデータは一周し予測値が一つずつ得られる。testデータは四周しているので平均する。\n",
    "\n",
    "def predict_cv(model, train_x, train_y, test_x):\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "\n",
    "    # クロスバリデーションで学習・予測を行い、予測値とインデックスを保存する\n",
    "    for i, (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(test_x)\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "\n",
    "    # バリデーションデータに対する予測値を連結し、その後元の順序に並べ直す\n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "\n",
    "    # テストデータに対する予測値の平均をとる\n",
    "    preds_test = np.mean(preds_test, axis=0)\n",
    "\n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1層目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.540879\teval-logloss:0.550034\n",
      "[1]\ttrain-logloss:0.452692\teval-logloss:0.47182\n",
      "[2]\ttrain-logloss:0.394818\teval-logloss:0.42026\n",
      "[3]\ttrain-logloss:0.351976\teval-logloss:0.385203\n",
      "[4]\ttrain-logloss:0.320213\teval-logloss:0.361498\n",
      "[5]\ttrain-logloss:0.296733\teval-logloss:0.344634\n",
      "[6]\ttrain-logloss:0.276105\teval-logloss:0.329003\n",
      "[7]\ttrain-logloss:0.258858\teval-logloss:0.316697\n",
      "[8]\ttrain-logloss:0.243628\teval-logloss:0.30775\n",
      "[9]\ttrain-logloss:0.231527\teval-logloss:0.300925\n",
      "[0]\ttrain-logloss:0.538915\teval-logloss:0.548639\n",
      "[1]\ttrain-logloss:0.452188\teval-logloss:0.471485\n",
      "[2]\ttrain-logloss:0.395742\teval-logloss:0.419976\n",
      "[3]\ttrain-logloss:0.354763\teval-logloss:0.384132\n",
      "[4]\ttrain-logloss:0.322183\teval-logloss:0.356264\n",
      "[5]\ttrain-logloss:0.299451\teval-logloss:0.339098\n",
      "[6]\ttrain-logloss:0.277833\teval-logloss:0.325516\n",
      "[7]\ttrain-logloss:0.263263\teval-logloss:0.315733\n",
      "[8]\ttrain-logloss:0.247804\teval-logloss:0.30592\n",
      "[9]\ttrain-logloss:0.233693\teval-logloss:0.295955\n",
      "[0]\ttrain-logloss:0.543319\teval-logloss:0.55058\n",
      "[1]\ttrain-logloss:0.454371\teval-logloss:0.468302\n",
      "[2]\ttrain-logloss:0.397123\teval-logloss:0.417626\n",
      "[3]\ttrain-logloss:0.354126\teval-logloss:0.380859\n",
      "[4]\ttrain-logloss:0.32187\teval-logloss:0.358236\n",
      "[5]\ttrain-logloss:0.297691\teval-logloss:0.338343\n",
      "[6]\ttrain-logloss:0.278216\teval-logloss:0.325787\n",
      "[7]\ttrain-logloss:0.260498\teval-logloss:0.313077\n",
      "[8]\ttrain-logloss:0.244367\teval-logloss:0.300156\n",
      "[9]\ttrain-logloss:0.230988\teval-logloss:0.293314\n",
      "[0]\ttrain-logloss:0.541658\teval-logloss:0.550119\n",
      "[1]\ttrain-logloss:0.453088\teval-logloss:0.469646\n",
      "[2]\ttrain-logloss:0.394388\teval-logloss:0.419325\n",
      "[3]\ttrain-logloss:0.353657\teval-logloss:0.382863\n",
      "[4]\ttrain-logloss:0.319021\teval-logloss:0.357915\n",
      "[5]\ttrain-logloss:0.291875\teval-logloss:0.338238\n",
      "[6]\ttrain-logloss:0.272894\teval-logloss:0.326276\n",
      "[7]\ttrain-logloss:0.256689\teval-logloss:0.315504\n",
      "[8]\ttrain-logloss:0.238942\teval-logloss:0.303753\n",
      "[9]\ttrain-logloss:0.227008\teval-logloss:0.296455\n",
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.4503 - val_loss: 0.3853\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.3629 - val_loss: 0.3826\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 0s 18us/step - loss: 0.3421 - val_loss: 0.3721\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 0s 18us/step - loss: 0.3199 - val_loss: 0.3645\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 0s 18us/step - loss: 0.3002 - val_loss: 0.3503\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 0s 18us/step - loss: 0.2716 - val_loss: 0.3400\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.2461 - val_loss: 0.3205\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.2168 - val_loss: 0.3102\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 0s 20us/step - loss: 0.1999 - val_loss: 0.3084\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 0s 20us/step - loss: 0.1823 - val_loss: 0.3066\n",
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 0.4488 - val_loss: 0.3748\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 0s 20us/step - loss: 0.3657 - val_loss: 0.3685\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 0s 18us/step - loss: 0.3498 - val_loss: 0.3561\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.3290 - val_loss: 0.3524\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 0s 20us/step - loss: 0.3033 - val_loss: 0.3356\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 0s 21us/step - loss: 0.2839 - val_loss: 0.3206\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 0s 21us/step - loss: 0.2497 - val_loss: 0.3042\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.2282 - val_loss: 0.2857\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 0s 24us/step - loss: 0.1999 - val_loss: 0.2771\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 0s 25us/step - loss: 0.1951 - val_loss: 0.2658\n",
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 0.4403 - val_loss: 0.3656\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.3682 - val_loss: 0.3518\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.3480 - val_loss: 0.3477\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.3273 - val_loss: 0.3352\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.3076 - val_loss: 0.3465\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.2826 - val_loss: 0.3100\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.2631 - val_loss: 0.2970\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.2267 - val_loss: 0.2740\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.2028 - val_loss: 0.2660\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.1882 - val_loss: 0.2713\n",
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 0.4586 - val_loss: 0.3673\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 0s 20us/step - loss: 0.3682 - val_loss: 0.3579\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 0s 18us/step - loss: 0.3468 - val_loss: 0.3565\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.3252 - val_loss: 0.3475\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 0s 18us/step - loss: 0.3055 - val_loss: 0.3437\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.2811 - val_loss: 0.3215\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 0s 18us/step - loss: 0.2558 - val_loss: 0.3056\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 0s 18us/step - loss: 0.2283 - val_loss: 0.2849\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.2018 - val_loss: 0.2806\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 0s 19us/step - loss: 0.1868 - val_loss: 0.2840\n"
     ]
    }
   ],
   "source": [
    "model_1a = Model1Xgb()\n",
    "pred_train_1a, pred_test_1a = predict_cv(model_1a, train_x, train_y, test_x)\n",
    "\n",
    "model_1b = Model1NN()\n",
    "pred_train_1b, pred_test_1b = predict_cv(model_1b, train_x_nn, train_y, test_x_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.2967\n",
      "logloss: 0.2819\n"
     ]
    }
   ],
   "source": [
    "# 1層目のモデルの評価\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1a, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1b, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測値を特徴量としてデータフレームを作成\n",
    "train_x_2 = pd.DataFrame({'pred_1a': pred_train_1a, 'pred_1b': pred_train_1b})\n",
    "test_x_2 = pd.DataFrame({'pred_1a': pred_test_1a, 'pred_1b': pred_test_1b})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2層目\n",
    "- 1層目の予測値だけを使用して学習を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.2508\n"
     ]
    }
   ],
   "source": [
    "model_2 = Model2Linear()\n",
    "pred_train_2, pred_test_2 = predict_cv(model_2, train_x_2, train_y, test_x_2)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_2, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⇒ 確かに2層にして求めたlog_lossのほうが小さくなった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
